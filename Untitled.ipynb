{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch import optim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        \n",
    "        self.labels = idx2numpy.convert_from_file(root+'/labels')\n",
    "        self.images = idx2numpy.convert_from_file(root+'/images')\n",
    "        print(self.labels)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        image = Image.fromarray( self.images[id] , 'L')\n",
    "        label = self.labels[id]\n",
    "        #print(label)\n",
    "        return self.transforms(image).view(-1), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([ transforms.Resize(26), transforms.ToTensor()])\n",
    "\n",
    "dataset = [MNIST('mnist/Train', transform), MNIST('mnist/Test', transform)]\n",
    "dataloader = [DataLoader(x, batch_size=128, shuffle=True, num_workers=0) for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New way of taking tensors. We do not have a separate computational graph. We just remember what everything is connected to and run a simple DFS style function backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To connect new tensors we have a simple method. When two tensors are active often, we make a connection. The architexture seems to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.1020,\n",
       "           0.2471, 0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.4000,\n",
       "           0.8118, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.5529,\n",
       "           0.7333, 0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.2000, 0.7490,\n",
       "           0.5373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.3804, 0.8431,\n",
       "           0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.6745, 0.7333,\n",
       "           0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.1647, 0.9216, 0.6588,\n",
       "           0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.3686, 0.9608, 0.6000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.5490, 0.8902, 0.2902,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.2118, 0.8667, 0.6902, 0.0431,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.4627, 0.9451, 0.5137, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0118, 0.6510, 0.8941, 0.2196, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.1529, 0.8510, 0.7216, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.4235, 0.9373, 0.5608, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5843, 0.9490, 0.4235, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0784, 0.7961, 0.9647, 0.2588, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3059, 0.8902, 0.8863, 0.1490, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.5529, 0.9490, 0.6353, 0.0235, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0196, 0.6196, 0.8039, 0.2510, 0.0039, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.1804, 0.2118, 0.0314, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000]]]),\n",
       " 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "tensor([1.])\n",
      "0\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-bc6eb2e48500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-bc6eb2e48500>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mcurrent_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_activations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0mcurrent_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_biases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_neuron_activations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mcurrent_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "# We will be very basic. For any two things that are activated together twice in a row, we will connect them.\n",
    "# Our update will be very simple. You take each self.neurons connections and just set the next rounds values to that at each step.\n",
    "# Then to backprop, you remember what each self.neuron has as its self.outputs and that will store your computational graph. Then backrpop. For now, I'm just usin ga massive\n",
    "# matrix to store connections.\n",
    "# We will store the self.neurons as a cube with shape 2 million total which will be a 26 by 26 by 26 for hte first cnn and then a 12 by1 12 for the dense layer then a final 10\n",
    "# To model the activations its probably easier to store them as a list. This will make it smaller. \n",
    "# For updating you look at the nodes in front of you. \n",
    "# Final thing to deal with negative numbers. A self.neuron can be either inhi\n",
    "class Model(torch.nn.Module):\n",
    "    # Initial connections are randomly formed\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.neuron_activations = [[[1]*26]*26]*26 # Where the final layer is supposed to be the dense one. This layer represents the activations\n",
    "        self.next_neuron_activations = np.zeros_like(self.neuron_activations)\n",
    "\n",
    "\n",
    "        self.outputs = [1]*10\n",
    "        self.outputs_inputs = np.zeros((10, 40, 3))\n",
    "        self.outputs_weights = [[1]*40]*10\n",
    "        self.neuron_inputs = np.zeros((26, 26, 26, 50, 3)) # 50 connections max for a self.neuron. 2 is because first three say which one. Next says weight. Final says gradients.\n",
    "        self.neuron_weights = [[[[1]*50]*26]*26]*26 # This is a list of torch tensors to make calculations easier\n",
    "        # We will delete connections over time.\n",
    "        #self.neuron_inputs = np.zeros_like(self.outputs) # Same thing for inputs\n",
    "        self.neuron_biases = torch.nn.Parameter(torch.zeros(26, 26, 26)+25) # Biases\n",
    "        # We estimate the inputs as roughly going forwards, but not necessarily\n",
    "        for layer in range(26):\n",
    "            self.neuron_inputs[layer,:,:,:,0] = (layer*abs(np.random.randn(1, 26, 26, 50))).clip(0, 25)\n",
    "            self.neuron_inputs[layer,:,:,:,1] = (np.random.randn(1, 26, 26, 50)*3+np.arange(26).reshape(1, 26, 1, 1)).clip(0, 25)\n",
    "            self.neuron_inputs[layer,:,:,:,2] = (np.random.randn(1, 26, 26, 50)*3+np.arange(26).reshape(1, 1, 26, 1)).clip(0, 26)\n",
    "        for i in range(26):\n",
    "            for j in range(26):\n",
    "                for k in range(26):\n",
    "                    for l in range(50):\n",
    "                        self.neuron_weights[i][j][k][l] = torch.nn.Parameter(torch.randn(1))\n",
    "                        self.neuron_activations[i][j][k] = torch.zeros(1)\n",
    "                        self.next_neuron_activations[i][j][k] = torch.zeros(1)\n",
    "        # For the self.outputs we select things from the final layer\n",
    "        self.outputs_inputs[:,:,0] = (26-np.random.randn(10, 40)*26).clip(0, 25)\n",
    "        self.outputs_inputs[:,:,1] = (26-np.random.randn(10, 40)*26).clip(0, 25)\n",
    "        self.outputs_inputs[:,:,2] = (26-np.random.randn(10, 40)*26).clip(0, 25)\n",
    "        for i in range(10):\n",
    "            for j in range(40):\n",
    "                self.outputs_weights[i][j] = torch.randn(1)\n",
    "                self.outputs[i] = torch.zeros(1)\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        # Loop through all self.neurons and then calculate the new value \n",
    "        for i in range(26):\n",
    "            print(i)\n",
    "            for j in range(26):\n",
    "                for k in range(26):\n",
    "                    current_sum=torch.zeros(1)\n",
    "                    for l in range(50):\n",
    "                        current_sum += self.neuron_activations[int(self.neuron_inputs[i, j, k, l, 0])][int(self.neuron_inputs[i, j, k, l, 1])][int(self.neuron_inputs[i, j, k, l, 2])]*self.neuron_weights[i][j][k][l]\n",
    "                    current_sum+=self.neuron_biases[i, j, k]\n",
    "                    self.next_neuron_activations[i][j][k] = torch.nn.ReLU()(current_sum)\n",
    "        for i in range(10):\n",
    "            current_sum=torch.zeros(1)\n",
    "            for j in range(40):\n",
    "                current_sum += self.neuron_activations[int(self.outputs_inputs[i, j, 0])][int(self.outputs_inputs[i, j, 1])][int(self.outputs_inputs[i, j, 2])]*self.outputs_weights[i][j]\n",
    "        \n",
    "            self.outputs[i] = torch.nn.ReLU()(current_sum)\n",
    "        self.neuron_activations = self.next_neuron_activations\n",
    "        for i in range(26):\n",
    "            for j in range(26):\n",
    "                for k in range(26):\n",
    "                    self.next_neuron_activations[i][j][k] = torch.zeros(1)\n",
    "                \n",
    "    def loss(self,correct):\n",
    "        s = torch.zeros(1)\n",
    "        for i in range(10):\n",
    "            if i != correct:\n",
    "                s+=self.outputs[i]\n",
    "            else:\n",
    "                s+=1-self.outputs[i]\n",
    "        return s\n",
    "model = Model()\n",
    "print('Initialized')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.6, momentum=0.9)\n",
    "for i in range(5):\n",
    "    img, label = dataset[1][i]\n",
    "    \n",
    "    for j in range(26):\n",
    "        for k in range(26):\n",
    "            model.neuron_activations[0][j][k] = img[0, i, j]\n",
    "    for _ in range(15):\n",
    "        optimizer.zero_grad()\n",
    "        model.update()\n",
    "        print(l)\n",
    "        l = model.loss(label)\n",
    "        optimizer.step()\n",
    "        del l\n",
    "    \n",
    "# Connection weights\n",
    "# If a self.neuron connection is not used,  \n",
    "# This will create connections \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n",
      "0\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n",
      "0\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n",
      "1\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "2\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "3\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "4\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "5\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "6\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "7\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "8\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "9\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "10\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "11\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "12\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "13\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "14\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<TanhBackward>)]\n",
      "tensor(1.)\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n",
      "0\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n",
      "1\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "2\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "3\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "4\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "5\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "6\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "7\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "8\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "9\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "10\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "11\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "12\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "13\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "14\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>), tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 1.]], grad_fn=<TanhBackward>)]\n",
      "tensor(126.0997)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "set_indices_and_values_unsafe is not allowed on a Tensor created from .data or .detach().\nIf your intent is to change the metadata of a Tensor (such as sizes / strides / storage / storage_offset)\nwithout autograd tracking the change, remove the .data / .detach() call and wrap the change in a `with torch.no_grad():` block.\nFor example, change:\n    x.data.set_(y)\nto:\n    with torch.no_grad():\n        x.set_(y)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-acc3c2a8308a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: set_indices_and_values_unsafe is not allowed on a Tensor created from .data or .detach().\nIf your intent is to change the metadata of a Tensor (such as sizes / strides / storage / storage_offset)\nwithout autograd tracking the change, remove the .data / .detach() call and wrap the change in a `with torch.no_grad():` block.\nFor example, change:\n    x.data.set_(y)\nto:\n    with torch.no_grad():\n        x.set_(y)"
     ]
    }
   ],
   "source": [
    "from torch import sparse\n",
    "import torch\n",
    "# Using sparse matrices after confirming that the above works.\n",
    "class Model(torch.nn.Module):\n",
    "    # Initial connections are randomly formed\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # Random Neron Structure\n",
    "        neurons = torch.arange(26*26*26).view(-1)\n",
    "        neurons = torch.cat(50*[neurons]).view(-1)\n",
    "        indices = torch.LongTensor(torch.randint(low=0, high=26*26*26, size=(26*26*26*50,))).view(-1)\n",
    "        i = torch.stack((neurons, indices))\n",
    "        values = torch.rand(26*26*26*50).view(-1)*2-1\n",
    "        self.neuron_weights_sparse = torch.nn.Parameter(torch.sparse.FloatTensor(i, values, torch.Size([26*26*26,26*26*26])))\n",
    "        self.neuron_activations = [torch.zeros(26*26*26).view(-1, 1)]\n",
    "        self.neuron_biases = torch.nn.Parameter(torch.zeros(26*26*26).view(-1, 1))\n",
    "        \n",
    "        # Outputs\n",
    "        outputs = torch.arange(10).view(-1)\n",
    "        outputs = torch.cat(50*[outputs]).view(-1)\n",
    "        indices = torch.LongTensor(torch.randint(low=0, high=26*26*26, size=(10*50,))).view(-1)\n",
    "        i = torch.stack((outputs, indices))\n",
    "        values = torch.rand(10*50).view(-1)\n",
    "        self.outputs_weights_sparse = torch.nn.Parameter(torch.sparse.FloatTensor(i, values, torch.Size([10, 26*26*26])))\n",
    "        self.outputs_activations = torch.zeros(10).view(-1, 1)\n",
    "        \n",
    "        # Inputs\n",
    "        neurons = torch.arange(26*26*26).view(-1)\n",
    "        neurons = torch.cat(20*[neurons]).view(-1)\n",
    "        indices = torch.LongTensor(torch.randint(low=0, high=26*26, size=(26*26*26*20,))).view(-1)\n",
    "        i = torch.stack((neurons, indices))\n",
    "        values = torch.rand(26*26*26*20).view(-1)*2-1\n",
    "        self.inputs_weights_sparse = torch.nn.Parameter(torch.sparse.FloatTensor(i, values, torch.Size([26*26*26,26*26])))\n",
    "        self.inputs_biases = torch.nn.Parameter(torch.zeros(26*26*26).view(-1, 1))\n",
    "        self.CSE = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def through_input(self, input_img):\n",
    "        \n",
    "        # Send input image into neurons\n",
    "        _=len(self.neuron_activations)-1\n",
    "        self.neuron_activations.append(torch.tanh(torch.sparse.addmm( mat=self.neuron_biases, mat2=input_img, mat1=self.inputs_weights_sparse)))\n",
    "        \n",
    "    def update(self):\n",
    "        \n",
    "        # Update the neurons\n",
    "        _=len(self.neuron_activations)-1\n",
    "        self.neuron_activations.append(torch.tanh(torch.sparse.addmm( mat=self.inputs_biases, mat2=self.neuron_activations[_], mat1=self.neuron_weights_sparse)))\n",
    "        \n",
    "        \n",
    "    def loss(self,correct):\n",
    "\n",
    "        # Update the outputs\n",
    "        _=len(self.neuron_activations)-1\n",
    "        self.outputs_activations = torch.sparse.mm(mat2=self.neuron_activations[_], mat1=self.outputs_weights_sparse)\n",
    "        #print(self.outputs_activations)\n",
    "        ideal = torch.zeros_like(self.outputs_activations)\n",
    "        ideal[correct] = 1\n",
    "        l = torch.sum(torch.square(self.outputs_activations-ideal))\n",
    "        return l\n",
    "    \n",
    "    def reset(self):\n",
    "        self.neuron_activations = [torch.zeros(26*26*26).view(-1, 1)]\n",
    "        \n",
    "model = Model()\n",
    "model.update(0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "losses = []\n",
    "for i in range(60):\n",
    "    model.reset()\n",
    "    img, label = dataset[1][i]\n",
    "    mode.through_input(img)\n",
    "    optimizer.zero_grad()\n",
    "    for _ in range(15):\n",
    "        model.update(_)\n",
    "    l = model.loss(label, 14)\n",
    "    l.backward(retain_graph=True)\n",
    "    print(l.data)\n",
    "    optimizer.step()\n",
    "    losses.append(l.data)\n",
    "    del l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]+=torch.Tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387]),\n",
       " tensor([0.5387])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MINST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-43ee99a8aa49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now we download MNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MINST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# process and save as torch files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5)\u001b[0m\n\u001b[1;32m     69\u001b[0m             urllib.request.urlretrieve(\n\u001b[1;32m     70\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_bar_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             )\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mgen_bar_updater\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_bar_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbar_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         self.container = self.status_printer(\n\u001b[0m\u001b[1;32m    224\u001b[0m             self.fp, total, self.desc, self.ncols)\n\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Prepare IPython progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# Now we download MNIST\n",
    "torchvision.datasets.MNIST('MINST', train = True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f76831c3400>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
